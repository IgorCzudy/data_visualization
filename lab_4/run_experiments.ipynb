{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from nets import *\n",
    "from results_and_plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/content/drive/My Drive'\n",
    "data_dir = parent_dir + '/TEAA/21x14'\n",
    "\n",
    "formats = [\n",
    "    '21x14', # 21 channels with spectrogram filtered to 8 values in the frequency domain + 6 time domain statistics: in total 294 dimensions\n",
    "    'pca136', # same than previous one after applying PCA conserving 99% of variance\n",
    "    'pca141' # same but using chb[1-16] for training and chb[17-24] for testing\n",
    "]\n",
    "\n",
    "configurations = [\n",
    "    LabConfiguration(FEEDFORWARD, feedforward_1, to_categorical = False, epochs = 5),\n",
    "    LabConfiguration(FEEDFORWARD, feedforward_2, to_categorical = True, epochs = 5),\n",
    "    LabConfiguration(FEEDFORWARD, feedforward_3, to_categorical = True, epochs = 5),\n",
    "    LabConfiguration(RECURRENT, rnn_1, to_categorical = True, timesteps = 10, epochs = 1),\n",
    "    LabConfiguration(RECURRENT, rnn_2, to_categorical = True, timesteps = 10, epochs = 1),\n",
    "    LabConfiguration(CONVOLUTIONAL, cnn_1, to_categorical = False, epochs = 5),\n",
    "    LabConfiguration(CONVOLUTIONAL, cnn_2, to_categorical = True, epochs = 5),\n",
    "    LabConfiguration(TDCNN, cnn_3, to_categorical = True, timesteps = 10, epochs = 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for format in formats:\n",
    "  train_lines, test_lines = get_train_and_test_sets(format, data_dir)\n",
    "  print(f\"Read {len(train_lines)} lines from train set and {len(test_lines)} from test set\")    \n",
    "\n",
    "  for binary_classification in [True, False]:\n",
    "\n",
    "    # get y data\n",
    "    train_set = [csv_to_tuple(l, False, binary_classification) for l in train_lines]\n",
    "    test_set  = [csv_to_tuple(l, False, binary_classification) for l in test_lines]\n",
    "    # num_channels = train_set[0][2].shape[0]\n",
    "\n",
    "    y_train = np.array([t[1] for t in train_set])\n",
    "    y_test  = np.array([t[1] for t in test_set])\n",
    "    labels = np.unique(y_train)\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                      classes = labels,\n",
    "                                                      y = y_train)\n",
    "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "\n",
    "    for conf in configurations:\n",
    "      if format != '21x24' and conf.model_type == TDCNN or conf.model_type == CONVOLUTIONAL:\n",
    "        continue\n",
    "\n",
    "      if conf.to_categorical:\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes = len(labels))\n",
    "        y_test  = keras.utils.to_categorical(y_test,  num_classes = len(labels))\n",
    "\n",
    "      # get X data\n",
    "      if conf.model_type == CONVOLUTIONAL:\n",
    "        train_set = reshape_dataset(train_set)\n",
    "        test_set = reshape_dataset(test_set)\n",
    "        X_train, X_test = prepare_x(train_set, test_set, conf.model_type, convolutional = True)\n",
    "        data = [(X_train, y_train), (X_test, y_test)]\n",
    "      else:\n",
    "        X_train, X_test = prepare_x(train_set, test_set, conf.model_type, convolutional = False)\n",
    "        data = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "      print(f\"Preprocessed data: {len(train_set)} train set {len(test_set)} test set\\nexample data: {train_set[0][0]}, label {train_set[0][1]}, x.shape = {train_set[0][2].shape}\")\n",
    "\n",
    "      # configure data generator and model\n",
    "      checkpoint_path = f\"{parent_dir}/TEAA/checkpoints/{format}_{conf.dnn.__name__}_{conf.epochs}_epochs_{'bin' if binary_classification else 'multi'}.ckpt\"\n",
    "      model_existed = False\n",
    "\n",
    "      if conf.model_type == RECURRENT or conf.model_type == TDCNN:\n",
    "        train_data_generator = MyDataGenerator(X_train, y_train,\n",
    "                                              shuffle = True,\n",
    "                                              timesteps = conf.timesteps,\n",
    "                                              batch_size = 50,\n",
    "                                              num_classes = len(labels),\n",
    "                                              to_categorical = True)\n",
    "        test_data_generator  = MyDataGenerator(X_test,  y_test,\n",
    "                                              shuffle = False,\n",
    "                                              timesteps = conf.timesteps,\n",
    "                                              batch_size = 50,\n",
    "                                              num_classes = len(labels),\n",
    "                                              to_categorical = True)\n",
    "\n",
    "        model = conf.dnn(input_shape = (conf.timesteps,) + X_train.shape[1:], num_labels = len(labels))\n",
    "\n",
    "      else:\n",
    "        train_data_generator = MyDataGeneratorToBalanceClasses(X_train, y_train,\n",
    "                                              shuffle = True,\n",
    "                                              batch_size = 100,\n",
    "                                              num_classes = len(labels),\n",
    "                                              to_categorical = True)\n",
    "        test_data_generator = None\n",
    "\n",
    "        model = conf.dnn(input_shape = X_train.shape[1:], num_labels = len(labels))\n",
    "      if os.path.isfile(f\"{checkpoint_path}.index\"):\n",
    "        model.load_weights(checkpoint_path)\n",
    "        model_existed = True\n",
    "        print(\"Read weights from checkpoint\")\n",
    "\n",
    "\n",
    "      print(model.summary())\n",
    "\n",
    "      if not model_existed:\n",
    "        # train model and save it\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "        cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        verbose=1)\n",
    "\n",
    "        if conf.model_type == RECURRENT:\n",
    "          model.fit(x = train_data_generator, epochs = 1, validation_data = test_data_generator,\n",
    "                    use_multiprocessing = False, callbacks=[cp_callback])\n",
    "        elif conf.model_type == TDCNN:\n",
    "          model.fit(x = train_data_generator, epochs = 10, validation_data = test_data_generator,\n",
    "                    use_multiprocessing = True, callbacks=[cp_callback])\n",
    "        else:\n",
    "          X_train, y_train = data[0]\n",
    "          X_test, y_test = data[1]\n",
    "          model.fit(x = train_data_generator, epochs = 5, validation_data = (X_test, y_test),\n",
    "                    class_weight = class_weights, use_multiprocessing = True,\n",
    "                    callbacks=[cp_callback])\n",
    "      else:\n",
    "        print(\"Not training, model existed\")\n",
    "\n",
    "      # get predictions\n",
    "      y_train_true, y_train_pred, y_test_true, y_test_pred = get_predictions(model, conf, y_train, y_test, X_train, X_test, train_data_generator, test_data_generator)\n",
    "\n",
    "      print(checkpoint_path)\n",
    "      show_results(y_train_true, y_train_pred, labels)\n",
    "      show_results(y_test_true, y_test_pred, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
